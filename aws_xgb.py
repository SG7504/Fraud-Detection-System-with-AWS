# -*- coding: utf-8 -*-
"""AWS_LGBM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sa0TEYOo6OBMYevfqk-PB5vW54XLQgzV
"""

# Install XGBoost if needed
!pip install xgboost --quiet

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_auc_score, cohen_kappa_score
)

# === Load Preprocessed Data ===
df = pd.read_csv('/content/combined_fraud_dataset.csv')

# === Clean NaN Values in Labels and Features ===
df = df.dropna(subset=['isFraud'])           # Drop rows where 'isFraud' is NaN
df = df.dropna(subset=['amount', 'source_encoded'])  # Also clean features if necessary

# === Prepare Features and Labels ===
X = df[['amount', 'source_encoded']]
y = df['isFraud']

# === Train/Test Split ===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# === Train XGBoost Model ===
model = xgb.XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),
    eval_metric='auc',
    learning_rate=0.05,
    n_estimators=100,
    max_depth=6,
    random_state=42,
    use_label_encoder=False
)

model.fit(X_train, y_train)

# === Predictions ===
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
y_test_proba = model.predict_proba(X_test)[:, 1]

# === Confusion Matrix ===
cm = confusion_matrix(y_test, y_test_pred)
tn, fp, fn, tp = cm.ravel()

# === Metrics ===
train_accuracy = accuracy_score(y_train, y_train_pred)
val_accuracy = accuracy_score(y_test, y_test_pred)
auc = roc_auc_score(y_test, y_test_proba)
tpr = tp / (tp + fn) if (tp + fn) != 0 else 0  # Recall (Sensitivity)
fpr = fp / (fp + tn) if (fp + tn) != 0 else 0  # False Positive Rate
specificity = tn / (tn + fp) if (tn + fp) != 0 else 0
fdr = fp / (fp + tp) if (fp + tp) != 0 else 0
kappa = cohen_kappa_score(y_test, y_test_pred)

# === Output ===
print("Training Accuracy:", round(train_accuracy, 4))
print("Validation Accuracy:", round(val_accuracy, 4))
print("ROC AUC Score:", round(auc, 4))
print("True Positive Rate (Recall):", round(tpr, 4))
print("False Positive Rate:", round(fpr, 4))
print("Specificity (TNR):", round(specificity, 4))
print("False Discovery Rate (FDR):", round(fdr, 4))
print("Cohen's Kappa:", round(kappa, 4))
print("\nClassification Report:\n", classification_report(y_test, y_test_pred))
print("Confusion Matrix:\n", cm)